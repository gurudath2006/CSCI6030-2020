{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How did you all behave? What a horrible idea! Oh no! Oh no! Where\n",
      "is your merit? What are you proud of? Ours are all apple-tarts. Not that she _wanted_ him to marry. not handsome--not at all handsome. What do you think of him? Were not you struck? What has\n",
      "he to do with books? They have more gentleness. I do not pretend to Emma's\n",
      "genius for foretelling and guessing. Her ignorance is hourly flattery. oh! She is loveliness itself. I will keep\n",
      "my ill-humour to myself. They were both in ecstasies. It is so with some men. In what respect? But how shall I do? how so? Will that do? What! Oh! But the case is altered now. The stupidest fellow! their luxury and ease. But ah! Ah! What can it possibly be? Do help me. Is it kingdom? Can it be woman? Can it be Neptune? Or a trident? or a mermaid? or a shark? Oh! Nonsense! their luxury and ease. That is _court_. But ah! It is a certainty. And so excellent in the Church! Dear me! If I had but her memory! but what shall you do? Heaven forbid! do the children grow? We are so very airy! What will it answer? There is jealousy. Have not I some right to complain? Oh! What! with the help of spectacles. It is such a blessing! That is what she writes about. There is no comparison between them. Just like her! The marriage of Lieut. Former provocations reappeared. Oh! Such a beautiful hind-quarter of pork! You are too bountiful! I do not pretend to it. Oh! Oh! Oh! Oh! Oh! Oh! Do not defer it. I do admire your patriotism. You will be adored in Highbury. He started. Good soul! Do not mimic her. You divert me against\n",
      "my conscience. Oh! He paused. She played. How is she to-day? We really are so shocked! Ah! Oh! Oh! There is no hurry at all. Look! It will be as clean as Randalls by candlelight. It regarded a supper-room. But fetch them both. Alas! How unlucky! Oh! Well! Her intentions were unchanged. These are the motives which I\n",
      "have been pressing on you. Oh! Absolutely insufferable! Worse and worse. Oh! Ah! How I catch myself out! Ah! They were sneering and negligent. Oh! she is absolutely charming! Oh! Heavens! The decree is issued by somebody. Oh! It is my daily errand. Oh! you are not serious now. Now do not you\n",
      "feel that you had? They vindicated him\n",
      "against the base aspersion. Wax-candles in the schoolroom! Oh! Have you finished it? Oh! Such an immense plantation all round it! Oh! They were interrupted. Better than nearer! The mistake had been slight. Oh! Ah! Don't disturb him. you are too obliging! Oh! I am all amazement! Oh! Soup too! Bless me! She did not regret it. Remember it? oh! Such a change! I am determined\n",
      "against all interference. just behind. They were entering the hall. Where is it? Interference--\n",
      "fruitless interference. Oh! Don't scruple. He did consent. But you were humble. That is your date. What shall we do to rouse them? They _shall_ talk. I will attack them with more address. I do not pretend to be a wit. Will you? I am in no hurry. I undertake the commission. The most unaccountable business! We both\n",
      "abhor suspense. You are not serious? Composure with a witness! Oh! I met him just now. No! Such a debasement on his! Oh! Pain is no expiation. Alas! WINDSOR-JULY. I behaved shamefully. Ah! Oh! she is a sweet creature! What a thinking brain\n",
      "you have! very unaccountable! Oh! but her lips were closed. He bowed. Is not she an angel in every gesture? FINIS\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import string\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords    \n",
    "\n",
    "\n",
    "# load data\n",
    "filename = '../datasets/shakespeare-DATA.txt'\n",
    "#file = open(filename, encoding=\"iso-8859-1\")\n",
    "file = open(filename, encoding=\"utf-8\")\n",
    "\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "We already have a sentence tokenizer, so we just need \n",
    "to run the sent_tokenize() method to create the array of sentences.\n",
    "'''\n",
    "# 1 Sentence Tokenize\n",
    "sentences = sent_tokenize(text)\n",
    "total_documents = len(sentences)\n",
    "#print(sentences)\n",
    "\n",
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n",
    "\n",
    "# 2 Create the Frequency matrix of the words in each sentence.\n",
    "freq_matrix = _create_frequency_matrix(sentences)\n",
    "#print(freq_matrix)\n",
    "\n",
    "'''\n",
    "Term frequency (TF) is how often a word appears in a document, divided by how many words are there in a document.\n",
    "'''\n",
    "\n",
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix\n",
    "\n",
    "# 3 Calculate TermFrequency and generate a matrix\n",
    "tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "#print(tf_matrix)\n",
    "\n",
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "# 4 creating table for documents per words\n",
    "count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "#print(count_doc_per_words)\n",
    "\n",
    "'''\n",
    "Inverse document frequency (IDF) is how unique or rare a word is.\n",
    "'''\n",
    "\n",
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "\n",
    "# 5 Calculate IDF and generate a matrix\n",
    "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "#print(idf_matrix)\n",
    "\n",
    "\n",
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix\n",
    "\n",
    "# 6 Calculate TF-IDF and generate a matrix\n",
    "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "#print(tf_idf_matrix)\n",
    "\n",
    "\n",
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentenceValue\n",
    "\n",
    "# 7 Important Algorithm: score the sentences\n",
    "sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "#print(sentence_scores)\n",
    "\n",
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average\n",
    "\n",
    "# 8 Find the threshold\n",
    "threshold = _find_average_score(sentence_scores)\n",
    "#print(threshold)\n",
    "\n",
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# 9 Important Algorithm: Generate the summary\n",
    "summary = _generate_summary(sentences, sentence_scores, 3 * threshold)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
